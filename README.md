<div align="center">
  <h1>ðŸš€ Bookmarks for DSAN-6725</h1>
  <p>
    A collection of useful links on GenAI (and related) collected from the web.<br>
    For helping keep pace with advancements in GenAI and in general helping with the DSAN-6725 course contents.
  </p>

  <p>
    <a href="#gen-ai">Gen-AI</a> â€¢
    <a href="#other-topics">Others</a> â€¢    
    <a href="#contributing">Contributing</a> â€¢
    <a href="#license">License</a>
  </p>
</div>

## Table of Contents

1. [Gen-AI](#gen-ai)
1. [Others](#others)
1. [Contributing](#contributing)
1. [License](#license)

## Gen-AI

### LLM Basics

| Category  | Link  | Description  |
|:----------|:----------|:----------|
| LLM Basics | [https://goyalpramod.github.io/blogs/Transformers_laid_out/](https://goyalpramod.github.io/blogs/Transformers_laid_out/) | Transformers explained (must read!) |
| LLM Basics | [https://youtu.be/Axd50ew4pco](https://youtu.be/Axd50ew4pco) | A short 4-minute video on CPU Vs GPU |
| LLM Basics | [https://x.com/Hesamation/status/1875376552374104300](https://x.com/Hesamation/status/1875376552374104300) | Temperature and LLM sampling process visualized in Excel |
| LLM Basics | [https://arxiv.org/pdf/2401.02038](https://arxiv.org/pdf/2401.02038) | Paper: Understanding LLMs: A Comprehensive Overview from Training to Inference|
| LLM Basics | [https://x.com/akshay_pachaar/status/1873345735250641173](https://x.com/akshay_pachaar/status/1873345735250641173) | What are Mixture of Experts (MoE)|
| LLM Basics | [https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-mixture-of-experts](https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-mixture-of-experts) | Visual introduction to Mixture-of-Experts|
| LLM Basics | [https://x.com/Hesamation/status/1872050437312147499](https://x.com/Hesamation/status/1872050437312147499) | Calculating GPU memory for serving LLMs|
| LLM Basics | [https://stackoverflow.blog/2023/11/09/an-intuitive-introduction-to-text-embeddings/](https://stackoverflow.blog/2023/11/09/an-intuitive-introduction-to-text-embeddings/) | Introduction to text embeddings|
| LLM Basics | [https://arxiv.org/abs/2501.00663](https://arxiv.org/abs/2501.00663) | Neural memory module for long-term sequence modeling|
| LLM Basics | [https://x.com/Aurimas_Gr/status/1876635530302992875](https://x.com/Aurimas_Gr/status/1876635530302992875) | Neural memory module for long-term sequence modeling|
| LLM Basics | [https://www.youtube.com/watch?v=h9Z4oGN89MU&t=663s](https://www.youtube.com/watch?v=h9Z4oGN89MU&t=663s) | Exploring GPU Architecture |


### Prompt engineering

| Category  | Link  | Description  |
|:----------|:----------|:----------|
| Prompt engineering | [https://x.com/tom_doerr/status/1875301168475467804](https://x.com/tom_doerr/status/1875301168475467804) | Ask `Claude` to write prompt for good code generation |
| Prompt engineering | [https://github.com/anthropics/prompt-eng-interactive-tutorial/tree/master](https://github.com/anthropics/prompt-eng-interactive-tutorial/tree/master) | Prompt engineering best practices for Anthropic Claude |
| Prompt engineering | [https://www.llama.com/docs/how-to-guides/prompting/](https://www.llama.com/docs/how-to-guides/prompting/) | Prompt engineering best practices for Meta Llama3 |
| Prompt engineering | [https://docs.aws.amazon.com/nova/latest/userguide/prompting.html](https://docs.aws.amazon.com/nova/latest/userguide/prompting.html) | Prompt engineering best practices for Amazon Nova |
| Prompt engineering | [https://ibm.github.io/watsonx-prompt-lab/lab-1/](https://ibm.github.io/watsonx-prompt-lab/lab-1/) | Prompt engineering best practices for watsonx.ai |
| Prompt engineering | [https://github.com/dair-ai/Prompt-Engineering-Guide?tab=readme-ov-file](https://github.com/dair-ai/Prompt-Engineering-Guide?tab=readme-ov-file) | Prompt engineering guide |
| Prompt engineering | [https://medium.com/@fareedkhandev/prompt-engineering-complete-guide-2968776f0431](https://medium.com/@fareedkhandev/prompt-engineering-complete-guide-2968776f0431) | Alternative prompt engineering guide |


### RAG

| Category  | Link  | Description  |
|:----------|:----------|:----------|
| RAG | [https://piotr-jurowiec.medium.com/retrieval-augmented-generation-in-business-applications-enhancing-efficiency-and-innovation-3c3886c88705](https://piotr-jurowiec.medium.com/retrieval-augmented-generation-in-business-applications-enhancing-efficiency-and-innovation-3c3886c88705) | Article: Retrieval-Augmented Generation in Business Applications |
| RAG | [https://arxiv.org/abs/2404.17723](https://arxiv.org/abs/2404.17723) | Paper: A Recent Study on RAG in NLP |
| RAG | [https://arxiv.org/pdf/2005.11401](https://arxiv.org/pdf/2005.11401) | Paper: Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks |
| RAG | [https://arxiv.org/pdf/2412.15605v1](https://arxiv.org/pdf/2412.15605v1) | Paper: Cache-augmented generation (CAG) as an alternative to RAG |
| RAG | [https://arxiv.org/pdf/2401.15884](https://arxiv.org/pdf/2401.15884) | Paper: Corrective Retrieval Augmented Generation |
| RAG | [https://arxiv.org/html/2409.13731v3](https://arxiv.org/html/2409.13731v3) | Paper: KAG: Boosting LLMs in Professional Domains via Knowledge Augmented Generation |
| RAG | [https://x.com/akshay_pachaar/status/1875520939536142656](https://x.com/akshay_pachaar/status/1875520939536142656) | Traditional RAG Vs Graph RAG |
| RAG | [https://www.dailydoseofds.com/p/traditional-rag-vs-hyde/](https://www.dailydoseofds.com/p/traditional-rag-vs-hyde/) | Traditional RAG Vs HyDE |
| RAG | [https://www.theunwindai.com/p/build-a-corrective-rag-agent](https://www.theunwindai.com/p/build-a-corrective-rag-agent) | Build a corrective RAG application |
| RAG | [https://x.com/Aurimas_Gr/status/1879148810158452777](https://x.com/Aurimas_Gr/status/1879148810158452777) | Challenges and components of production-grade RAG AI systems |
| RAG | [https://x.com/akshay_pachaar/status/1879154648327811134](https://x.com/akshay_pachaar/status/1879154648327811134) | Building a multi-tenant RAG app with easy integrations |
| RAG | [https://x.com/akshay_pachaar/status/1878916141122462139](https://x.com/akshay_pachaar/status/1878916141122462139) | MemoRAG enhances RAG with long-term memory capabilities |
| RAG | [https://arxiv.org/pdf/2412.15605v1](https://arxiv.org/pdf/2412.15605v1) | Cache-augmented generation (CAG) as an alternative to RAG |
| RAG | [https://div.beehiiv.com/](https://div.beehiiv.com/) | Great Blog Series on RAG, Agents, and Other Cutting-Edge Gen-AI Topics |
| RAG | [https://www.anthropic.com/news/contextual-retrieval](https://www.anthropic.com/news/contextual-retrieval) | Introducing Contextual Retrieval |
| RAG | [https://aws.amazon.com/what-is/retrieval-augmented-generation/](https://aws.amazon.com/what-is/retrieval-augmented-generation/) | AWS Introduction to RAG |
| RAG | [https://arxiv.org/pdf/2312.10997](https://arxiv.org/pdf/2312.10997) | Retrieval-Augmented Generation for Large Language Models: A Survey |


### Agents
| Category  | Link  | Description  |
|:----------|:----------|:----------|
| Agents | [https://www.kaggle.com/whitepaper-agents](https://www.kaggle.com/whitepaper-agents) | Google's whitepaper on Agents |
| Agents | [https://medium.com/@goutham_nivass/agentic-workflow-amazon-bedrock-and-crewai-3a1a0597a2ce](https://medium.com/@goutham_nivass/agentic-workflow-amazon-bedrock-and-crewai-3a1a0597a2ce) | Agentic Workflow: Amazon Bedrock and CrewAI |
| Agents | [https://github.com/SamuelSchmidgall/AgentLaboratory](https://github.com/SamuelSchmidgall/AgentLaboratory) | Autonomous LLM-driven research workflow for scientific projects |
| Agents | [https://github.com/inferablehq](https://github.com/inferablehq) | Open-source platform for building agentic automations |
| Agents | [https://www.newsletter.swirlai.com/p/building-ai-agents-from-scratch-part](https://www.newsletter.swirlai.com/p/building-ai-agents-from-scratch-part) | Guide to building AI agents from scratch |
| Agents | [https://huyenchip.com//2025/01/07/agents.html](https://huyenchip.com//2025/01/07/agents.html) | Overview of intelligent AI agents, tools, and planning |
| Agents | [https://medium.com/@thomas.latterner/ai-agents-what-are-they-50ced8323b9a](https://medium.com/@thomas.latterner/ai-agents-what-are-they-50ced8323b9a) | Overview of AI Agents |
| Agents | [https://www.letta.com/blog/ai-agents-stack](https://www.letta.com/blog/ai-agents-stack) | The Agents Stack |
| Agents | [https://www.mongodb.com/pt-br/library/resources/ai-agents?x=inokiP](https://www.mongodb.com/pt-br/library/resources/ai-agents?x=inokiP) | Demystifying AI Agents: A Guide for Beginners |


### Guardrails

| Category  | Link  | Description  |
|:----------|:----------|:----------|
| Guardrails | [https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-are-ai-guardrails](https://www.mckinsey.com/featured-insights/mckinsey-explainers/what-are-ai-guardrails) | Overview of guardrails: definition, utility, implementation ideas, deployment |

### Benchmarking

| Category  | Link  | Description  |
|:----------|:----------|:----------|
| Benchmarking | [https://magazine.sebastianraschka.com/p/ai-research-papers-2024-part-2](https://magazine.sebastianraschka.com/p/ai-research-papers-2024-part-2)| Summary of influential AI research papers from 2024 |

### Fine-tuning

| Category  | Link  | Description  |
|:----------|:----------|:----------|
| Fine-tuning | [https://docs.unsloth.ai/basics/tutorial-how-to-finetune-llama-3-and-use-in-ollama](https://docs.unsloth.ai/basics/tutorial-how-to-finetune-llama-3-and-use-in-ollama)| Fine-tuning LLMs with Unsloth.ai |
| Fine-tuning | [https://www.kaggle.com/code/iamleonie/fine-tuning-gemma-2-jpn-for-yomigana-with-lora](https://www.kaggle.com/code/iamleonie/fine-tuning-gemma-2-jpn-for-yomigana-with-lora)| Fine-tuning Gemma 2 JPN for Yomigana using LoRA |
| Fine-tuning | [https://www.youtube.com/watch?v=b80by3Xk_A8](https://www.youtube.com/watch?v=b80by3Xk_A8)| Stanfordâ€™s Hugging Face Transformers fine-tuning course |
| Fine-tuning | [https://www.sciencedirect.com/science/article/pii/S0950584924001289](https://www.sciencedirect.com/science/article/pii/S0950584924001289)| Automating Fine-tuning of LLM's using Prompt Engineering Techniques |
| Fine-tuning | [https://arxiv.org/abs/2310.00035](https://arxiv.org/abs/2310.00035)| Usage of LoRA for LLM fine-tuning |
| Fine-tuning | [https://arxiv.org/abs/2502.06807](https://arxiv.org/abs/2502.06807) | Large reasoning models: Generalized vs Domain-specific |
| Fine-tuning | [https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.1_(8B)-GRPO.ipynb](https://colab.research.google.com/github/unslothai/notebooks/blob/main/nb/Llama3.1_(8B)-GRPO.ipynb) | Using GRPO RL algorithm to train LLama-3.1 |



### Responsible AI

| Category  | Link  | Description  |
|:----------|:----------|:----------|
| Responsible AI | [https://www.aisnakeoil.com/](https://www.aisnakeoil.com/)| Debunking AI hype |
| Responsible AI | [https://learn.microsoft.com/en-us/azure/machine-learning/concept-responsible-ai](https://learn.microsoft.com/en-us/azure/machine-learning/concept-responsible-ai)| Overview of Microsoft's Responsible AI framework |
| Responsible AI | [https://oecd.ai/en/ai-principles](https://oecd.ai/en/ai-principles)| OECD AI Principles |

### Apps

| Category  | Link  | Description  |
|:----------|:----------|:----------|
| Apps | [https://bi.new/](https://bi.new/) | Build live BI dashboards using Gen AI |
| Apps | [https://github.com/patchy631/ai-engineering-hub](https://github.com/patchy631/ai-engineering-hub) | Code samples for RAG, Agents and everything LLM related |
| Apps | [https://github.com/cyclotruc/gitingest](https://github.com/cyclotruc/gitingest) | Turn any code based into a text ingest of its code |
| Apps | [https://github.com/browser-use/browser-use](https://github.com/browser-use/browser-use) | Make websites accessible to AI agents |
| Apps | [https://www.linkedin.com/blog/engineering/ai/practical-text-to-sql-for-data-analytics](https://www.linkedin.com/blog/engineering/ai/practical-text-to-sql-for-data-analytics)| How LinkedIn built text-to-sql for data analytics|
| Apps | [https://x.com/sharifshameem/status/1872880360922726667](https://x.com/sharifshameem/status/1872880360922726667) | A vibe based book search engine app built with Claude |
| Apps | [https://github.com/egoist/sitefetch](https://github.com/egoist/sitefetch) | Tool for fetching and saving website content as text |
| Apps | [https://data-people-group.github.io/blogs/2025/01/13/docwrangler/](https://data-people-group.github.io/blogs/2025/01/13/docwrangler/) | Interactive LLM-powered data processing with DocWrangler |
| Apps | [https://github.com/CatchTheTornado/text-extract-api](https://github.com/CatchTheTornado/text-extract-api) | IOCR API for document conversion to text/JSON |
| Apps | [https://github.com/docsifyjs/docsify](https://github.com/docsifyjs/docsify) | Lightweight documentation site generator using Markdown |
| Apps | [https://github.com/nanbingxyz/5ire](https://github.com/nanbingxyz/5ire) | Cross-platform AI assistant with local knowledge base support |
| Apps | [https://github.com/BuilderIO/gpt-crawler](https://github.com/BuilderIO/gpt-crawler) | Crawl a site to generate knowledge files |
| Apps | [https://github.com/open-webui/open-webui](https://github.com/open-webui/open-webui) | Open-source web UI for LLM, Ollama |
| Apps | [https://github.com/comfyanonymous/ComfyUI](https://github.com/comfyanonymous/ComfyUI) | diffusion model GUI, api with a nodes interface |
| Apps | [https://link-springer-com.proxy.library.georgetown.edu/article/10.1007/s10639-024-12537-x](https://link-springer-com.proxy.library.georgetown.edu/article/10.1007/s10639-024-12537-x) | Using GPT to generate math word problems with difficulty levels |


## Others

| Category  | Link  | Description  |
|:----------|:----------|:----------|
| Git | [https://x.com/ChShersh/status/1875495972593131561](https://x.com/ChShersh/status/1875495972593131561) | A very short list of useful `git` commands |
| Python | [https://www.dailydoseofds.com/p/pandas-vs-fireducks-performance-comparison/](https://www.dailydoseofds.com/p/pandas-vs-fireducks-performance-comparison/) | Pands Vs Fireducks |
| Deepseek | [https://github.com/deepseek-ai/DeepSeek-Coder](https://github.com/deepseek-ai/DeepSeek-Coder) | Open-source AI code generation model |


## Significant Papers in GenAI Pre-training and Fine-tuning
| Paper  | Link  | Description  |
|:----------|:----------|:----------|
| Train Short, Test Long: Attention with Linear Biases Enables Input Length Extrapolation | https://arxiv.org/abs/2108.12409  https://github.com/ofirpress/attention_with_linear_biases.git | A training technique in Language Models to intensify their generalization ability |


## Contributing

Fork this repo and submit a PR to get any link you would like to get included into this repo. Follow these instructions while making contributions:

1. Add your contribution as a line in the markdown table, make sure to view the rendered README to confirm that the table formatting is not broken.
1. Make sure that you put an appropriate value in the `Cateogry` field and useful information in the `Description` field (the description should not exceed 10-words).
1. If you are using an existing `Category` then add your line just after the last line in that `Category`'s table. If you want to add a new category then create a new section for it similar to the other sections.
1. Prefer adding actionable content such as a code sample or a blog post with code. If you are adding a link to a paper then also include a link to its associated GitHub code repo.

## License

This library is licensed under the MIT-0 License. See the [`LICENSE`](./LICENSE) file.
